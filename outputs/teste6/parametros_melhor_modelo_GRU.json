{"max_steps": 3000, "learning_rate": 0.001, "batch_size": 32, "encoder_hidden_size": 200, "decoder_hidden_size": 200, "encoder_n_layers": 2, "decoder_layers": 2, "context_size": 10, "encoder_activation": "tanh", "encoder_bias": true, "encoder_dropout": 0.0, "num_lr_decays": -1, "early_stop_patience_steps": -1, "val_check_steps": 100, "scaler_type": "robust", "random_seed": 1}